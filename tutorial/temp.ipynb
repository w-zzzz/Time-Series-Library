{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from scipy.signal import welch, find_peaks, hilbert, butter, filtfilt\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def is_valid_data(values, min_length=2, min_std=1e-8):\n",
    "    return len(values) >= min_length and np.std(values) >= min_std\n",
    "\n",
    "def calculate_mean(values):\n",
    "    return np.mean(values) if len(values) > 0 else np.nan\n",
    "\n",
    "def calculate_std(values):\n",
    "    return np.std(values) if len(values) > 0 else np.nan\n",
    "\n",
    "def calculate_windowed_std(values, window_size=128):\n",
    "    if len(values) < window_size:\n",
    "        return np.std(values) if len(values) > 1 else np.nan  # Use global std if insufficient data\n",
    "    \n",
    "    windowed_std = [np.std(values[i:i+window_size]) for i in range(len(values) - window_size + 1)]\n",
    "    return np.std(windowed_std)\n",
    "\n",
    "def calculate_windowed_entropy(values, window_size=128):\n",
    "    if len(values) < window_size:\n",
    "        if len(values) > 1: # Use global std if insufficient data\n",
    "            histogram, _ = np.histogram(np.std(values), bins='auto', density=True) \n",
    "            return entropy(histogram)\n",
    "    else:\n",
    "        windowed_std = [\n",
    "            np.std(values[i:i+window_size])\n",
    "            for i in range(len(values) - window_size + 1)\n",
    "        ]\n",
    "        histogram, _ = np.histogram(windowed_std, bins='auto', density=True)\n",
    "        return entropy(histogram)\n",
    "\n",
    "def calculate_min(values):\n",
    "    return np.min(values) if len(values) > 0 else np.nan\n",
    "\n",
    "def calculate_max(values):\n",
    "    return np.max(values) if len(values) > 0 else np.nan\n",
    "\n",
    "def calculate_median(values):\n",
    "    return np.median(values) if len(values) > 0 else np.nan\n",
    "\n",
    "def calculate_skewness(values):\n",
    "    if not is_valid_data(values, min_length=3):\n",
    "        return np.nan\n",
    "    return skew(values)\n",
    "\n",
    "def calculate_kurtosis(values):\n",
    "    if not is_valid_data(values, min_length=4):\n",
    "        return np.nan\n",
    "    return kurtosis(values)\n",
    "\n",
    "def calculate_rms(values):\n",
    "    return np.sqrt(np.mean(np.square(values))) if len(values) > 0 else np.nan\n",
    "\n",
    "def calculate_rms_filtered(values, fs = 64, freq_band = (0.1, 0.5)):\n",
    "    \"\"\"\n",
    "    Calculate the RMS of a signal after filtering for a specific frequency band.\n",
    "\n",
    "    Parameters:\n",
    "    - values (array-like): Input signal values.\n",
    "    - fs (float): Sampling frequency of the signal.\n",
    "    - freq_band (tuple): Frequency band for filtering as (low_freq, high_freq).\n",
    "\n",
    "    Returns:\n",
    "    - float: RMS value of the filtered signal, or NaN if the input is invalid.\n",
    "    \"\"\"\n",
    "    padlen = 27\n",
    "    if len(values) == 0 or len(values) <= padlen or fs <= 0 or not (isinstance(freq_band, tuple) and len(freq_band) == 2):\n",
    "        return np.nan\n",
    "\n",
    "    # Design a bandpass filter\n",
    "    low, high = freq_band\n",
    "    nyquist = 0.5 * fs\n",
    "    low = low / nyquist\n",
    "    high = high / nyquist\n",
    "\n",
    "    # Check frequency band validity\n",
    "    if low <= 0 or high >= 1 or low >= high:\n",
    "        return np.nan\n",
    "\n",
    "    # Butterworth filter design\n",
    "    b, a = butter(N=4, Wn=[low, high], btype='band')\n",
    "\n",
    "    # Apply the filter\n",
    "    filtered_values = filtfilt(b, a, values)\n",
    "\n",
    "    # Calculate RMS of the filtered signal\n",
    "    rms_value = np.sqrt(np.mean(np.square(filtered_values)))\n",
    "    return rms_value\n",
    "\n",
    "def calculate_iqr(values):\n",
    "    if len(values) > 0:\n",
    "        return np.percentile(values, 75) - np.percentile(values, 25)\n",
    "    return np.nan\n",
    "\n",
    "def calculate_line_length(values):\n",
    "    return 10 * 64 * np.sum(np.abs(np.diff(values))) / (len(values) - 1) if len(values) > 1 else np.nan\n",
    "\n",
    "def calculate_variance_of_amplitude(values):\n",
    "    if not is_valid_data(values, min_length=2):\n",
    "        return np.nan\n",
    "    return np.var(values)\n",
    "\n",
    "def calculate_slope_of_amplitude_changes(values):\n",
    "    diff_values = np.diff(values)\n",
    "    return np.mean(diff_values) if len(diff_values) > 0 else np.nan\n",
    "\n",
    "def calculate_amplitude_envelope(values):\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    analytic_signal = hilbert(values)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    return np.mean(amplitude_envelope)\n",
    "\n",
    "def calculate_zero_crossing_rate(values):\n",
    "    return 64 * 10 * ((values[:-1] * values[1:]) < 0).sum() / len(values) if len(values) > 1 else np.nan\n",
    "\n",
    "def calculate_threshold_zero_crossing_rate(values, threshold_fraction=0.1):\n",
    "    if len(values) <= 1:\n",
    "        return np.nan\n",
    "    max_amplitude = np.max(np.abs(values))\n",
    "    threshold = max_amplitude * threshold_fraction\n",
    "    crossing_count = ((values[:-1] < -threshold) & (values[1:] >= -threshold)) | \\\n",
    "                     ((values[:-1] > threshold) & (values[1:] <= threshold))\n",
    "    return 64 * 10 * np.sum(crossing_count) / len(values)\n",
    "\n",
    "def calculate_threshold_zero_crossing_rate_adaptive(values, window_size=100, threshold_fraction=0.1):\n",
    "    if len(values) <= 1 or len(values) < window_size:\n",
    "        return np.nan\n",
    "    zcr = []\n",
    "    for i in range(0, len(values) - window_size + 1, window_size):\n",
    "        window = values[i:i+window_size]\n",
    "        threshold = np.max(np.abs(window)) * threshold_fraction\n",
    "        crossings = ((window[:-1] < -threshold) & (window[1:] >= -threshold)) | \\\n",
    "                    ((window[:-1] > threshold) & (window[1:] <= threshold))\n",
    "        zcr.append(np.sum(crossings) / window_size)\n",
    "    return np.mean(zcr)\n",
    "\n",
    "def calculate_autocorrelation(values):\n",
    "    values = np.array(values)\n",
    "    if len(values) < 2 or np.std(values) < 1e-8:\n",
    "        return np.nan\n",
    "    autocorr = np.corrcoef(values[:-1], values[1:])[0, 1]\n",
    "    return autocorr if not np.isnan(autocorr) else np.nan\n",
    "\n",
    "def calculate_autocorrelation_multi_lag(values, max_lag=320):\n",
    "    if len(values) <= max_lag:\n",
    "        return np.nan\n",
    "    autocorrs = [np.corrcoef(values[:-lag], values[lag:])[0, 1] for lag in range(192, max_lag+1)]\n",
    "    autocorrs = [ac for ac in autocorrs if not np.isnan(ac)]\n",
    "    return np.mean(autocorrs) if autocorrs else np.nan\n",
    "\n",
    "# def find_pos_neg_peaks(values, prominence=0.3, distance=128, height=0.8, width=50):\n",
    "# def find_pos_neg_peaks(values, prominence=0.1, distance=64, height=0.3, width=50):\n",
    "def find_pos_neg_peaks(values, prominence=0, distance=1, height=0, width=0):\n",
    "    peaks_pos, properties_pos = find_peaks(values, prominence=prominence, distance=distance, height=height, width=width)\n",
    "    peaks_neg, properties_neg = find_peaks(-values, prominence=prominence, distance=distance, height=height, width=width)\n",
    "    peaks = np.concatenate((peaks_pos, peaks_neg), axis=0)\n",
    "    properties = {**properties_pos, **properties_neg}\n",
    "    return peaks, properties\n",
    "\n",
    "def calculate_peak_to_peak(values):\n",
    "    values = np.array(values)\n",
    "    return np.ptp(values) if len(values) > 0 else np.nan\n",
    "\n",
    "def calculate_number_of_peaks(values):\n",
    "    # Find peaks with specified prominence and minimum distance between peaks\n",
    "    peaks, properties = find_pos_neg_peaks(values)\n",
    "\n",
    "    # Calculate the number of peaks normalized by the signal length\n",
    "    return 10 * 64 * len(peaks) / (len(values) - 1)\n",
    "\n",
    "def calculate_peak_prominence(values):\n",
    "    # peaks, properties = find_peaks(values, prominence=1)\n",
    "    peaks, properties = find_pos_neg_peaks(values)\n",
    "\n",
    "    return np.mean(properties['prominences']) if len(peaks) > 0 else np.nan\n",
    "\n",
    "def calculate_peak_width(values):\n",
    "    peaks, properties = find_pos_neg_peaks(values)\n",
    "\n",
    "    return np.mean(properties['widths']) if 'widths' in properties and len(peaks) > 0 else np.nan\n",
    "\n",
    "def calculate_peak_to_peak_variability(values):\n",
    "    peaks, properties = find_pos_neg_peaks(values)\n",
    "    \n",
    "    # Calculate distances between consecutive peaks\n",
    "    if len(peaks) < 2:\n",
    "        return np.nan  # Not enough peaks to calculate variability\n",
    "    \n",
    "    peak_to_peak_distances = np.diff(peaks)\n",
    "    \n",
    "    # Calculate variability (standard deviation of distances)\n",
    "    return np.std(peak_to_peak_distances)\n",
    "\n",
    "def calculate_power_spectral_density(values, sampling_rate=64.0, window='hamming'):\n",
    "    if len(values) < 1:\n",
    "        return np.nan\n",
    "    nperseg = min(256, len(values))\n",
    "    if nperseg < 1:\n",
    "        return np.nan\n",
    "    f, Pxx = welch(values, fs=sampling_rate, nperseg=nperseg, window=window)\n",
    "    return np.sum(Pxx)\n",
    "\n",
    "def calculate_band_power(values, sampling_rate=64.0, bands=[(0.1, 0.5), (0.5, 1)], window='hamming'):\n",
    "    if len(values) < 1:\n",
    "        # return [np.nan] * len(bands)\n",
    "        return np.nan\n",
    "    f, Pxx = welch(values, fs=sampling_rate, nperseg=min(256, len(values)), window=window)\n",
    "    band_powers = []\n",
    "    for (low, high) in bands:\n",
    "        idx_band = np.logical_and(f >= low, f <= high)\n",
    "        band_power = np.trapz(Pxx[idx_band], f[idx_band])\n",
    "        band_powers.append(band_power)\n",
    "    return band_powers[0]\n",
    "\n",
    "def calculate_spectral_entropy(values, sampling_rate=64.0, window='hamming'):\n",
    "    if len(values) < 1:\n",
    "        return np.nan\n",
    "    nperseg = min(256, len(values))\n",
    "    if nperseg < 1:\n",
    "        return np.nan\n",
    "    f, Pxx = welch(values, fs=sampling_rate, nperseg=nperseg, window=window)\n",
    "    \n",
    "    # Total power\n",
    "    total_power = np.sum(Pxx)\n",
    "    # Spectral Entropy\n",
    "    normalized_psd = Pxx / total_power if total_power > 0 else np.zeros_like(Pxx)\n",
    "    spectral_entropy = entropy(normalized_psd, base=2)\n",
    "    return spectral_entropy\n",
    "\n",
    "def calculate_shannon_entropy(values):\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    hist, _ = np.histogram(values, bins='fd', density=True)  # 'fd' is the Freedman-Diaconis rule\n",
    "    hist = hist[hist > 0]\n",
    "    hist_sum = hist.sum()\n",
    "    if hist_sum == 0:\n",
    "        return np.nan\n",
    "    return -np.sum(hist * np.log(hist)) / hist_sum\n",
    "\n",
    "def calculate_dominant_frequency(values, sampling_rate=64.0, window='hamming'):\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    nperseg = min(256, len(values))\n",
    "    try:\n",
    "        f, Pxx = welch(values, fs=sampling_rate, nperseg=nperseg, window=window)\n",
    "        if len(Pxx) == 0:\n",
    "            return np.nan\n",
    "        dominant_freq = f[np.argmax(Pxx)]\n",
    "        return dominant_freq\n",
    "    except Exception as e:\n",
    "        # Log the exception if needed\n",
    "        return np.nan\n",
    "\n",
    "def calculate_wavelet_coefficients(values, wavelet='harr', level=3):\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    # Dynamic level adjustment\n",
    "    max_level = int(np.floor(np.log2(len(values))))\n",
    "    level = min(max_level, level)\n",
    "    if level < 1:\n",
    "        return np.nan  # Insufficient length for even one level\n",
    "    try:\n",
    "        coeffs = pywt.wavedec(values, wavelet, level=level)\n",
    "        # Example: Return the mean of the approximation coefficients at the highest level\n",
    "        return np.mean(coeffs[0]) if len(coeffs[0]) > 0 else np.nan\n",
    "    except Exception as e:\n",
    "        # Log the exception if needed\n",
    "        return np.nan\n",
    "    \n",
    "def calculate_wavelet_sum(values, wavelet='harr', level=5):\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    # Dynamic level adjustment\n",
    "    max_level = int(np.floor(np.log2(len(values))))\n",
    "    level = min(max_level, level)\n",
    "    if level < 1:\n",
    "        return np.nan  # Insufficient length for even one level\n",
    "    try:\n",
    "        coeffs = pywt.wavedec(values, wavelet, level=level)\n",
    "        # Example: Return the mean of the approximation coefficients at the highest level\n",
    "        return sum(np.sum(np.abs(c)) / len(c) for c in coeffs if len(c) > 0)\n",
    "    except Exception as e:\n",
    "        # Log the exception if needed\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "FEATURE_FUNCTIONS = {\n",
    "    'Mean': calculate_mean,\n",
    "    'Std': calculate_std,\n",
    "    'WindowStd': calculate_windowed_std,\n",
    "    'WindowEntropy': calculate_windowed_entropy,\n",
    "    'Min': calculate_min,\n",
    "    'Max': calculate_max,\n",
    "    'Median': calculate_median,\n",
    "    'Skewness': calculate_skewness,\n",
    "    'Kurtosis': calculate_kurtosis,\n",
    "    'RMS': calculate_rms,\n",
    "    'RMS_filtered': calculate_rms_filtered,\n",
    "    'IQR': calculate_iqr,\n",
    "    'LineLength': calculate_line_length,\n",
    "    'Variance': calculate_variance_of_amplitude,\n",
    "    'Slope': calculate_slope_of_amplitude_changes,\n",
    "    'ZeroCrossingRate': calculate_zero_crossing_rate,\n",
    "    'ThresholdZCR': calculate_threshold_zero_crossing_rate,\n",
    "    'Autocorrelation': calculate_autocorrelation,\n",
    "    'AutocorrelationLagged': calculate_autocorrelation_multi_lag,\n",
    "    'PeakToPeak': calculate_peak_to_peak,\n",
    "    'NumPeaks': calculate_number_of_peaks,\n",
    "    'PeakProminence': calculate_peak_prominence,\n",
    "    'PeakWidth': calculate_peak_width,\n",
    "    'PeakVariance': calculate_peak_to_peak_variability,\n",
    "    'PowerSpectralDensity': calculate_power_spectral_density,\n",
    "    'BandPower': calculate_band_power,\n",
    "    'SpectralEntropy': calculate_spectral_entropy,\n",
    "    'ShannonEntropy': calculate_shannon_entropy,\n",
    "    'DominantFrequency': calculate_dominant_frequency,\n",
    "    'WaveletCoeff': calculate_wavelet_coefficients,\n",
    "    'WaveletSum': calculate_wavelet_sum,\n",
    "    'AmplitudeEnvelope': calculate_amplitude_envelope\n",
    "    # Add more features as needed\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "stats_entry = {}\n",
    "for signal in signal_list:\n",
    "    exact_values = occurrence_entry.get(f'Exact_{signal}', [])\n",
    "    head_tail_values = occurrence_entry.get(f'Head_Tail_{signal}', [])\n",
    "\n",
    "    stats_entry[signal] = {\n",
    "        'Exact': {feature: func(exact_values) for feature, func in FEATURE_FUNCTIONS.items()},\n",
    "        'Head_Tail': {feature: func(head_tail_values) for feature, func in FEATURE_FUNCTIONS.items()}\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
